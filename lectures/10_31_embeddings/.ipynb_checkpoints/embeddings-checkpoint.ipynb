{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings\n",
    "\n",
    "<br>\n",
    "\n",
    "[<img width=400 src=\"https://upload.wikimedia.org/wikipedia/commons/f/fe/Kernel_Machine.svg\">](https://en.wikipedia.org/wiki/Word_embedding)\n",
    "\n",
    "Word embeddings are algorithms that represent categorical data like words as vectors in a high dimensional space. \n",
    "These are machine learning methods that construct the embedding vectors using cooccurrence statistics, expressed in terms of simple language models. Embeddings reveal surprising semantic relations encoded in linear relationships. But they are \"data hungry\" and require large corpora of text or other coocurrence data to construct good embeddings. \n",
    "\n",
    "In this notebook we will explore some of the basics of word embeddings, playing around with two types of embeddings constructed on large amounts of text extracted from [Wikipedia](https://en.wikipedia.org/wiki/Main_Page). There are several tutorials on the web for this material; one is [here](https://medium.com/swlh/playing-with-word-vectors-308ab2faa519).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, load in the usual modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "import os\n",
    "# this turns off some pesky warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=Warning)\n",
    "\n",
    "# direct plots to appear within the cell, and set their style\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [gensim package](https://radimrehurek.com/gensim/index.html), already familiar to us from our foray into topic models. The following bit of code reads in 100-dimensional embedding vectors, trained using the [GloVe](https://nlp.stanford.edu/projects/glove/) algorithm on a collection of Wikipedia data. Specifically, it uses 6 billion tokens of Wikipedia, with a 400,000 word vocabulary. You can find other precompiled embeddings [here](https://www.diycode.cc/projects/RaRe-Technologies/gensim-data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader as gdl\n",
    "from gensim.models import KeyedVectors\n",
    "glove = gdl.load(\"glove-wiki-gigaword-100\")\n",
    "# glove has 100-dimensional word embeddings, \n",
    "# trained on 1 billion words from wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore these embeddings a bit. Here is the vector for 'yale'. Pretty interesting, huh?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7831  ,  0.51717 , -0.38207 , -0.23722 , -0.31616 ,  0.30805 ,\n",
       "        0.7639  ,  0.064106, -0.74913 ,  0.60586 , -0.23871 , -0.16876 ,\n",
       "       -0.25634 ,  1.0727  , -0.29968 ,  0.020095,  0.54501 , -0.17847 ,\n",
       "       -0.26676 , -0.11798 , -0.48692 ,  0.22712 ,  0.017473, -0.4747  ,\n",
       "        0.44861 , -0.084281, -0.30413 , -1.1351  , -0.14869 , -0.11182 ,\n",
       "       -0.3253  ,  1.0029  , -0.35742 ,  0.35149 , -1.1068  , -0.064142,\n",
       "       -0.72284 ,  0.14114 , -0.41247 , -0.16184 , -0.54577 , -0.12958 ,\n",
       "       -0.88356 , -0.089722,  0.10555 , -0.12288 ,  0.92851 ,  0.50032 ,\n",
       "        0.1349  ,  0.21457 ,  0.35074 , -0.73133 ,  0.39633 , -0.4324  ,\n",
       "       -0.38816 , -1.3467  ,  0.37464 , -0.79386 ,  0.11185 ,  0.18007 ,\n",
       "       -0.75143 ,  0.24975 , -0.094948, -0.36341 ,  0.2487  , -0.22667 ,\n",
       "        0.32289 ,  1.2949  ,  0.42658 ,  1.2912  , -0.13954 ,  0.68976 ,\n",
       "        0.21587 ,  0.13715 , -1.0092  ,  0.028827,  0.11011 , -0.1912  ,\n",
       "       -0.073198, -0.52449 ,  0.49199 ,  0.14463 , -0.18844 , -0.75536 ,\n",
       "       -0.28704 ,  0.019113,  0.30349 , -0.74425 , -0.072221, -0.40647 ,\n",
       "        0.26899 , -0.28318 ,  0.7241  ,  0.50796 , -0.37846 , -0.13008 ,\n",
       "       -0.13808 ,  0.098928,  0.16216 ,  0.16293 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['yale']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now let's see which vectors are closest to the 'yale' vector. This is a little more interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glove.most_similar('yale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explore word similarity using embeddings.  \n",
    "\n",
    "Now, create a few cells where you use the `most_similar` function to find similar words to a few words that you select. Add some markdown to describe your findings, and why they do and do not seem to make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code and markdown go here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at some of the components of the embedding vectors. What do the distributions of values look like?\n",
    "We'll first pull out the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab = set([w for w in glove.vocab])\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individually, each vector embedding looks like gaussian noise. but together, the components are strongly correlated and generate a normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 50 # we'll look at this component\n",
    "\n",
    "x = [] # this will be a list of all 400,000 values, one for each word in the vocabulary\n",
    "for w in vocab:\n",
    "    x.append(glove[w][i])\n",
    "\n",
    "ax = sns.distplot(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate a scatter plot\n",
    "\n",
    "Now, generate a scatter plot of a few <i>pairs</i> of components. For example, you could extract the first and second components of all the embedding vectors. What do you see? Describe the distributions of points. Do they look random?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and markdown go here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploring analogies\n",
    "\n",
    "Now we'll explore how analogies are \"solved\" using the embeddings. Here is the canonical example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698541283607483),\n",
       " ('monarch', 0.6843380928039551),\n",
       " ('throne', 0.6755735874176025),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534753799438),\n",
       " ('prince', 0.6517034769058228),\n",
       " ('elizabeth', 0.6464517712593079),\n",
       " ('mother', 0.6311717629432678),\n",
       " ('emperor', 0.6106470823287964),\n",
       " ('wife', 0.6098655462265015)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar(positive=['king', 'woman'], negative=['man'])\n",
    "# i.e. king + woman - man === king - man + woman === queen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that to get the top choice, you can just do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('queen', 0.7698541283607483)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar(positive=['king', 'woman'], negative=['man'])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar(positive=['king', 'woman'], negative=['man'])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now choose at least five analogies. Which of the analogies do the models \"get right\"? Which are clearly wrong? Describe your findings and speculate on some reasons that the model might miss some of the analogies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('maoism', 0.47466930747032166),\n",
       " ('krasin', 0.47244420647621155),\n",
       " ('meteor', 0.45975160598754883),\n",
       " ('marxism-leninism', 0.4591567814350128),\n",
       " ('cosmology', 0.4494326114654541),\n",
       " ('deuterium', 0.4467034935951233),\n",
       " ('superconductivity', 0.44532275199890137),\n",
       " ('helium', 0.4438009262084961),\n",
       " ('shortie', 0.4427167773246765),\n",
       " ('phlogiston', 0.44135400652885437)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar(positive=['', 'physics'], negative=['neuroscience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
